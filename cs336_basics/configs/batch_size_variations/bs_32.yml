run:
  wandb_tags: ["batch-size-variations"]

optimizer:
  lr: 2.7e-3

training:
  batch_size: 32
  max_steps: 40_000
  eval_interval: 2_000
  eval_steps: 20
  eval_batch_size: 32
  checkpoint_interval: 40_000
  lr_max: 2.7e-3
  warmup_ratio: 0.1