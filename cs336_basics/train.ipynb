{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: mps\n",
      "step    1 | loss: 9.259974 | lr: 1.0000e-04 | pre-clip norm: 1.1611 | dt: 313.03ms | tok/sec: 6542.40\n",
      "step    1 | validation loss: 9.152950\n",
      "saved checkpoint to ../out/run-1/checkpoints/checkpoint_1.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from cs336_basics.adamw import AdamW\n",
    "from cs336_basics.transformer import Transformer\n",
    "from cs336_basics.data_loader import get_batch\n",
    "from cs336_basics.loss import cross_entropy_loss\n",
    "from cs336_basics.gradient_clip import gradient_clip\n",
    "from cs336_basics.lr_cosine_schedule import lr_cosine_schedule\n",
    "\n",
    "# ====================================== Device detection ======================================\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "# ====================================== Configuration ======================================\n",
    "\n",
    "config = {\n",
    "    \"device\": device,\n",
    "    \"dtype\": torch.bfloat16 if device == \"cuda\" else torch.float32,\n",
    "}\n",
    "\n",
    "config[\"model\"] = {\n",
    "    \"d_model\": 512,\n",
    "    \"num_heads\": 16,\n",
    "    \"d_ff\": 1344,\n",
    "    \"vocab_size\": 10_000,\n",
    "    \"context_length\": 256,\n",
    "    \"num_layers\": 4,\n",
    "    \"rope_theta\": 1e4,\n",
    "    \"device\": config[\"device\"],\n",
    "    \"dtype\": config[\"dtype\"],\n",
    "}\n",
    "\n",
    "config[\"optimizer\"] = {\n",
    "    \"lr\": 1e-3,\n",
    "    \"betas\": (0.9, 0.999),\n",
    "    \"eps\": 1e-8,\n",
    "    \"weight_decay\": 1e-2,\n",
    "}\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 8\n",
    "max_steps = 1\n",
    "\n",
    "eval_before_training = False\n",
    "eval_interval = 40 # will also auto-eval after training\n",
    "eval_iters = 1\n",
    "eval_batch_size = 8\n",
    "\n",
    "max_l2_norm = 1.0 # for gradient clipping\n",
    "\n",
    "lr_max = 1e-3\n",
    "lr_min = lr_max * 0.1\n",
    "warmup_iters = 0.1 * max_steps\n",
    "cosine_cycle_iters = 0.9 * max_steps\n",
    "\n",
    "train_data_path = \"../out/ts-train-tokens.bin\"\n",
    "valid_data_path = \"../out/ts-valid-tokens.bin\"\n",
    "\n",
    "run_id = \"run-1\"\n",
    "run_dir = f\"../out/{run_id}\"\n",
    "checkpoint_dir = f\"{run_dir}/checkpoints\"\n",
    "checkpoint_interval = 100 # will also auto-save after training\n",
    "\n",
    "log_dir = f\"{run_dir}\" # keep this option in case user wants to change\n",
    "log_file = f\"{log_dir}/log.txt\"\n",
    "\n",
    "# ====================================== Training loop ======================================\n",
    "\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "with open(log_file, \"w\") as f:  # open for writing to clear the file\n",
    "    pass\n",
    "\n",
    "train_data = np.memmap(train_data_path, dtype=np.uint16, mode=\"r\")\n",
    "valid_data = np.memmap(valid_data_path, dtype=np.uint16, mode=\"r\")\n",
    "\n",
    "model = Transformer(**config[\"model\"])\n",
    "model.to(config[\"device\"])\n",
    "\n",
    "use_compile = True\n",
    "if use_compile and device != \"mps\":\n",
    "    model = torch.compile(model)\n",
    "elif use_compile and device == \"mps\":\n",
    "    model = torch.compile(model, backend=\"aot_eager\")\n",
    "\n",
    "optimizer = AdamW(model.parameters(), **config[\"optimizer\"])\n",
    "\n",
    "def log(message: str):\n",
    "    print(message)\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(message + \"\\n\")\n",
    "\n",
    "def evaluate(step: int):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for _ in range(eval_iters):\n",
    "            x, y = get_batch(valid_data, eval_batch_size, config[\"model\"][\"context_length\"], config[\"device\"])\n",
    "            logits = model(x)\n",
    "            loss = cross_entropy_loss(logits, y)\n",
    "            val_loss += loss.item()\n",
    "        val_loss /= eval_iters\n",
    "        \n",
    "        log(f\"step {step:4d} | validation loss: {val_loss:.6f}\")\n",
    "\n",
    "\n",
    "def save_checkpoint(step: int):\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_{step}.pt\")\n",
    "    torch.save(\n",
    "        {\n",
    "            \"model\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"step\": step,\n",
    "            \"config\": config,\n",
    "        },\n",
    "        checkpoint_path,\n",
    "    )\n",
    "    log(f\"saved checkpoint to {checkpoint_path}\")\n",
    "\n",
    "\n",
    "if eval_before_training:\n",
    "    evaluate(0)\n",
    "\n",
    "for step in range(1, max_steps + 1):\n",
    "    t0 = time.time()\n",
    "    is_last_step = step == max_steps\n",
    "\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    x, y = get_batch(train_data, batch_size, config[\"model\"][\"context_length\"], config[\"device\"])\n",
    "\n",
    "    logits = model(x)\n",
    "    loss = cross_entropy_loss(logits, y)\n",
    "    loss.backward()\n",
    "    norm = gradient_clip(model.parameters(), max_l2_norm)  # norm before clipping\n",
    "\n",
    "    lr = lr_cosine_schedule(step, lr_max, lr_min, warmup_iters, cosine_cycle_iters)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    t1 = time.time()\n",
    "    dt = t1 - t0\n",
    "    tokens_per_sec = config[\"model\"][\"context_length\"] * batch_size / dt\n",
    "    log(\n",
    "        f\"step {step:4d} | loss: {loss.item():.6f} | lr: {lr:.4e} | pre-clip norm: {norm:.4f} | dt: {dt * 1000:.2f}ms | tok/sec: {tokens_per_sec:.2f}\"\n",
    "    )\n",
    "\n",
    "    if step % eval_interval == 0 or is_last_step:\n",
    "        evaluate(step)\n",
    "\n",
    "    if step % checkpoint_interval == 0 or is_last_step:\n",
    "        save_checkpoint(step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
