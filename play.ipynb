{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(b'i', b'n'), (b' ', b't'), (b's', b't'), (b' ', b'a'), (b'e', b'r'), (b'e', b'n'), (b'in', b'g'), (b' t', b'h'), (b' ', b'f'), (b't', b'e'), (b'r', b'e'), (b'a', b't'), (b' ', b'b'), (b'o', b'n'), (b' t', b'o'), (b'o', b'u'), (b' ', b's'), (b' ', b'm'), (b'l', b'e'), (b' ', b'in'), (b'k', b'en'), (b' ', b'o'), (b'a', b'b'), (b' ', b'p'), (b'r', b'a'), (b' ', b'v'), (b' ', b'i'), (b'g', b'e'), (b'ra', b'in'), (b' th', b'e'), (b'c', b't'), (b'i', b'on'), (b' ', b'('), (b'y', b'te'), (b' v', b'o'), (b' vo', b'c'), (b' voc', b'ab'), (b'l', b'a'), (b' ', b're'), (b' a', b'n'), (b' t', b'rain'), (b't', b'h'), (b'la', b'r'), (b'r', b'o'), (b't', b'o'), (b'u', b'n'), (b' t', b'e'), (b' ', b'B'), (b' B', b'P'), (b' BP', b'E'), (b' train', b'ing'), (b'l', b'd'), (b' ', b'w'), (b' ', b'd'), (b' vocab', b'u'), (b' vocabu', b'lar'), (b' vocabular', b'y'), (b'to', b'ken'), (b'l', b'i'), (b' th', b'at'), (b'v', b'e'), (b'ou', b'r'), (b'l', b'l'), (b' b', b'yte'), (b'e', b'd'), (b' m', b'er'), (b' o', b'f'), (b'ct', b'ion'), (b' to', b'ken'), (b'i', b'z'), (b'ou', b'ld'), (b'a', b'l'), (b' an', b'd'), (b'p', b'e'), (b' ', b'li'), (b' li', b'st'), (b' ', b'T'), (b' ', b'n'), (b' mer', b'ge'), (b' byte', b's'), (b'p', b'le'), (b'en', b't'), (b' b', b'e'), (b' ', b'c'), (b' te', b'st'), (b' ', b'y'), (b'o', b'r'), (b' f', b'un'), (b' fun', b'ction'), (b'u', b't'), (b' s', b'h'), (b' sh', b'ould'), (b' p', b'a'), (b'st', b'r'), (b' ', b'P'), (b' w', b'i'), (b' ', b'A'), (b' m', b'a'), (b'i', b'al'), (b' f', b'ro'), (b' fro', b'm'), (b' T', b'h'), (b'i', b's'), (b' merge', b's'), (b'p', b'p'), (b' i', b's'), (b' o', b'r'), (b'm', b'ent'), (b'at', b'h'), (b' in', b'p'), (b' inp', b'ut'), (b' f', b'i'), (b' token', b'iz'), (b' tokeniz', b'er'), (b' ', b'Y'), (b' Y', b'our'), (b'a', b'n'), (b'a', b'st'), (b'm', b'e'), (b't', b'er'), (b'e', b's'), (b' p', b'ro'), (b' s', b'pe'), (b' spe', b'c'), (b' spec', b'ial'), (b')', b'.'), (b' d', b'o'), (b' n', b'o'), (b' ', b'<'), (b'd', b'er'), (b'at', b'ion'), (b' test', b's'), (b' y', b'ou'), (b' i', b'm'), (b' im', b'ple'), (b' imple', b'ment'), (b'a', b'd'), (b'r', b'un'), (b' ', b'u'), (b'k', b'e'), (b's', b'ing'), (b' P', b'y'), (b'u', b'i'), (b'l', b'y'), (b' s', b'u'), (b' re', b'ge'), (b' rege', b'x'), (b' ', b'W'), (b'v', b'en'), (b' te', b'x'), (b' tex', b't'), (b' fi', b'le'), (b'b', b'yte'), (b' ', b'h'), (b' ', b'le'), (b'o', b'w'), (b'ter', b's'), (b' ', b'str'), (b' wi', b'th'), (b'iz', b'e'), (b' in', b't'), (b's', b'i'), (b'i', b've'), (b'in', b'es'), (b'u', b'm'), (b' i', b'te'), (b' ite', b'm'), (b' pro', b'd'), (b' prod', b'u'), (b' produ', b'c'), (b' produc', b'ed'), (b' an', b'y'), (b' token', b's'), (b' a', b'd'), (b' no', b't'), (b'e', b'ct'), (b't', b'u'), (b's', b'u'), (b' d', b'i'), (b' Th', b'e'), (b' ', b'I'), (b'c', b'h'), (b')', b','), (b'a', b's'), (b' or', b'der'), (b' y', b'our'), (b' wi', b'll'), (b' n', b'e'), (b'a', b'p'), (b't', b'rain'), (b'b', b'pe'), (b' ', b'run'), (b'p', b'y'), (b' ', b'O'), (b't', b's'), (b' m', b'e'), (b' u', b'sing'), (b'g', b'u'), (b'a', b'ge'), (b' f', b'or'), (b' th', b'is'), (b' Py', b'th'), (b' Pyth', b'on'), (b' ma', b'ke'), (b' su', b're'), (b'a', b've'), (b' b', b'ui'), (b' bui', b'ld'), (b'pp', b'or'), (b' m', b'o'), (b' mo', b'st'), (b' f', b'ast'), (b'D', b'e'), (b'De', b'li'), (b'Deli', b'v'), (b'Deliv', b'er'), (b'Deliver', b'ab'), (b'Deliverab', b'le'), (b' W', b'r'), (b' Wr', b'i'), (b' Wri', b'te'), (b' ', b'g'), (b' g', b'i'), (b' gi', b'ven'), (b' p', b'ath'), (b' train', b's'), (b'le', b've'), (b'leve', b'l'), (b' h', b'an'), (b' han', b'd'), (b' hand', b'le'), (b' le', b'ast'), (b' f', b'o'), (b' fo', b'll'), (b' foll', b'ow'), (b' follow', b'ing'), (b' pa', b'ra'), (b' para', b'me'), (b' parame', b'ters'), (b'p', b'ath'), (b' P', b'ath'), (b' d', b'at'), (b' dat', b'a'), (b's', b'ize'), (b' p', b'o'), (b' po', b'si'), (b' posi', b't'), (b' posit', b'ive'), (b' in', b'te'), (b' inte', b'g'), (b' integ', b'er'), (b' d', b'e'), (b' de', b'f'), (b' def', b'ines'), (b' ma', b'x'), (b' max', b'i'), (b' maxi', b'm'), (b' maxim', b'um'), (b' f', b'in'), (b' fin', b'al'), (b' s', b'ize'), (b'in', b'c'), (b'inc', b'l'), (b'incl', b'u'), (b'inclu', b'd'), (b'includ', b'ing'), (b' in', b'i'), (b' ini', b't'), (b' init', b'ial'), (b' item', b's'), (b' mer', b'g'), (b' merg', b'ing'), (b'token', b's'), (b' str', b'ing'), (b' string', b's'), (b' ad', b'd'), (b' Th', b'es'), (b' Thes', b'e'), (b' o', b'th'), (b' oth', b'er'), (b' other', b'w'), (b' otherw', b'is'), (b' otherwis', b'e'), (b' a', b'f'), (b' af', b'f'), (b' aff', b'ect'), (b' re', b'tu'), (b' retu', b'r'), (b' retur', b'n'), (b' re', b'su'), (b' resu', b'l'), (b' resul', b't'), (b' result', b'ing'), (b' di', b'ct'), (b'in', b't'), (b' ma', b'pp'), (b' mapp', b'ing'), (b' I', b'D'), (b'tu', b'ple'), (b'byte', b's'), (b']', b']'), (b' ', b'E'), (b' E', b'a'), (b' Ea', b'ch'), (b' t', b'u'), (b' tu', b'ple'), (b' (', b'<'), (b'>', b','), (b'>', b'),'), (b' re', b'p'), (b' rep', b're'), (b' repre', b's'), (b' repres', b'ent'), (b' represent', b'ing'), (b' w', b'as'), (b' merge', b'd'), (b'>', b'.'), (b' order', b'ed'), (b' b', b'y'), (b' c', b're'), (b' cre', b'ation'), (b' T', b'o'), (b' a', b'g'), (b' ag', b'a'), (b' aga', b'in'), (b' again', b'st'), (b' ', b'our'), (b' pro', b'v'), (b' prov', b'i'), (b' provi', b'd'), (b' provid', b'ed'), (b' fi', b'r'), (b' fir', b'st'), (b' ne', b'ed'), (b' ad', b'ap'), (b' adap', b'ter'), (b' a', b't'), (b' ', b'['), (b'ad', b'ap'), (b'adap', b'ters'), (b']', b'.'), (b' Th', b'en'), (b' u', b'v'), (b' p', b'yte'), (b' pyte', b'st'), (b'te', b'st'), (b' implement', b'ation'), (b' a', b'b'), (b' ab', b'le'), (b' pa', b's'), (b' pas', b's'), (b' a', b'll'), (b' O', b'p'), (b' Op', b't'), (b' Opt', b'ion'), (b' Option', b'a'), (b' Optiona', b'll'), (b' Optionall', b'y'), (b'th', b'is'), (b' c', b'ould'), (b' ', b'lar'), (b' lar', b'ge'), (b' t', b'i'), (b' ti', b'me'), (b'in', b've'), (b'inve', b'st'), (b'invest', b'ment'), (b' c', b'an'), (b' ', b'ke'), (b' ke', b'y'), (b' pa', b'r'), (b' par', b'ts'), (b' me', b'th'), (b' meth', b'o'), (b' metho', b'd'), (b' s', b'o'), (b' so', b'me'), (b' s', b'y'), (b' sy', b'st'), (b' syst', b'e'), (b' syste', b'm'), (b' system', b's'), (b' ', b'la'), (b' la', b'n'), (b' lan', b'gu'), (b' langu', b'age'), (b' in', b'st'), (b' inst', b'an'), (b' instan', b'c'), (b' instanc', b'e'), (b' ', b'C'), (b'+', b'+'), (b'c', b'on'), (b'con', b'si'), (b'consi', b'der'), (b' c', b'pp'), (b' cpp', b'y'), (b' cppy', b'y'), (b' ', b'R'), (b' R', b'u'), (b' Ru', b'st'), (b'u', b'sing'), (b' Py', b'O'), (b' I', b'f'), (b' a', b'w'), (b' aw', b'a'), (b' awa', b're'), (b' w', b'h'), (b' wh', b'i'), (b' whi', b'ch'), (b' o', b'p'), (b' op', b'er'), (b' oper', b'ation'), (b' operation', b's'), (b' re', b'q'), (b' req', b'ui'), (b' requi', b're'), (b' c', b'o'), (b' co', b'py'), (b' copy', b'ing'), (b' v', b's'), (b' re', b'ad'), (b' read', b'ing'), (b' di', b're'), (b' dire', b'ct'), (b' direct', b'ly'), (b' me', b'm'), (b' mem', b'or'), (b' memor', b'y'), (b' le', b'ave'), (b' in', b'str'), (b' instr', b'u'), (b' instru', b'ction'), (b' instruction', b's'), (b' i', b't'), (b' build', b's'), (b' ', b'on'), (b' on', b'ly'), (b' p', b'y'), (b' py', b'p'), (b' pyp', b'ro'), (b' pypro', b'j'), (b' pyproj', b'ect'), (b'to', b'm'), (b'tom', b'l'), (b' A', b'l'), (b' Al', b's'), (b' Als', b'o'), (b' no', b'te'), (b' ', b'G'), (b' G', b'P'), (b' GP', b'T'), (b' w', b'e'), (b' we', b'll'), (b'su', b'ppor'), (b'suppor', b'te'), (b'supporte', b'd'), (b' ', b'en'), (b' en', b'g'), (b' eng', b'ines'), (b' to', b'o'), (b' s', b'l'), (b' sl', b'ow'), (b' W', b'e'), (b' h', b'ave'), (b' v', b'er'), (b' ver', b'i'), (b' veri', b'f'), (b' verif', b'i'), (b' verifi', b'ed'), (b' O', b'n'), (b' On', b'i'), (b' Oni', b'gu'), (b' Onigu', b'r'), (b' Onigur', b'um'), (b' Onigurum', b'a'), (b' re', b'as'), (b' reas', b'on'), (b' reason', b'ab'), (b' reasonab', b'ly'), (b' su', b'ppor'), (b' suppor', b'ts'), (b' ne', b'g'), (b' neg', b'at'), (b' negat', b'ive'), (b' ', b'l'), (b' l', b'o'), (b' lo', b'o'), (b' loo', b'k'), (b' look', b'a'), (b' looka', b'h'), (b' lookah', b'e'), (b' lookahe', b'ad'), (b' b', b'ut'), (b' pa', b'c'), (b' pac', b'k'), (b' pack', b'age'), (b' i', b'f'), (b' any', b'th'), (b' anyth', b'ing'), (b' ', b'e'), (b' e', b'ven'), (b' fast', b'er')]\n",
      "{'<|endoftext|>': 0, '\\x00': 1, '\\x01': 2, '\\x02': 3, '\\x03': 4, '\\x04': 5, '\\x05': 6, '\\x06': 7, '\\x07': 8, '\\x08': 9, '\\t': 10, '\\n': 11, '\\x0b': 12, '\\x0c': 13, '\\r': 14, '\\x0e': 15, '\\x0f': 16, '\\x10': 17, '\\x11': 18, '\\x12': 19, '\\x13': 20, '\\x14': 21, '\\x15': 22, '\\x16': 23, '\\x17': 24, '\\x18': 25, '\\x19': 26, '\\x1a': 27, '\\x1b': 28, '\\x1c': 29, '\\x1d': 30, '\\x1e': 31, '\\x1f': 32, ' ': 33, '!': 34, '\"': 35, '#': 36, '$': 37, '%': 38, '&': 39, \"'\": 40, '(': 41, ')': 42, '*': 43, '+': 44, ',': 45, '-': 46, '.': 47, '/': 48, '0': 49, '1': 50, '2': 51, '3': 52, '4': 53, '5': 54, '6': 55, '7': 56, '8': 57, '9': 58, ':': 59, ';': 60, '<': 61, '=': 62, '>': 63, '?': 64, '@': 65, 'A': 66, 'B': 67, 'C': 68, 'D': 69, 'E': 70, 'F': 71, 'G': 72, 'H': 73, 'I': 74, 'J': 75, 'K': 76, 'L': 77, 'M': 78, 'N': 79, 'O': 80, 'P': 81, 'Q': 82, 'R': 83, 'S': 84, 'T': 85, 'U': 86, 'V': 87, 'W': 88, 'X': 89, 'Y': 90, 'Z': 91, '[': 92, '\\\\': 93, ']': 94, '^': 95, '_': 96, '`': 97, 'a': 98, 'b': 99, 'c': 100, 'd': 101, 'e': 102, 'f': 103, 'g': 104, 'h': 105, 'i': 106, 'j': 107, 'k': 108, 'l': 109, 'm': 110, 'n': 111, 'o': 112, 'p': 113, 'q': 114, 'r': 115, 's': 116, 't': 117, 'u': 118, 'v': 119, 'w': 120, 'x': 121, 'y': 122, 'z': 123, '{': 124, '|': 125, '}': 126, '~': 127, '\\x7f': 128, '\\x80': 129, '\\x81': 130, '\\x82': 131, '\\x83': 132, '\\x84': 133, '\\x85': 134, '\\x86': 135, '\\x87': 136, '\\x88': 137, '\\x89': 138, '\\x8a': 139, '\\x8b': 140, '\\x8c': 141, '\\x8d': 142, '\\x8e': 143, '\\x8f': 144, '\\x90': 145, '\\x91': 146, '\\x92': 147, '\\x93': 148, '\\x94': 149, '\\x95': 150, '\\x96': 151, '\\x97': 152, '\\x98': 153, '\\x99': 154, '\\x9a': 155, '\\x9b': 156, '\\x9c': 157, '\\x9d': 158, '\\x9e': 159, '\\x9f': 160, '\\xa0': 161, '¡': 162, '¢': 163, '£': 164, '¤': 165, '¥': 166, '¦': 167, '§': 168, '¨': 169, '©': 170, 'ª': 171, '«': 172, '¬': 173, '\\xad': 174, '®': 175, '¯': 176, '°': 177, '±': 178, '²': 179, '³': 180, '´': 181, 'µ': 182, '¶': 183, '·': 184, '¸': 185, '¹': 186, 'º': 187, '»': 188, '¼': 189, '½': 190, '¾': 191, '¿': 192, 'À': 193, 'Á': 194, 'Â': 195, 'Ã': 196, 'Ä': 197, 'Å': 198, 'Æ': 199, 'Ç': 200, 'È': 201, 'É': 202, 'Ê': 203, 'Ë': 204, 'Ì': 205, 'Í': 206, 'Î': 207, 'Ï': 208, 'Ð': 209, 'Ñ': 210, 'Ò': 211, 'Ó': 212, 'Ô': 213, 'Õ': 214, 'Ö': 215, '×': 216, 'Ø': 217, 'Ù': 218, 'Ú': 219, 'Û': 220, 'Ü': 221, 'Ý': 222, 'Þ': 223, 'ß': 224, 'à': 225, 'á': 226, 'â': 227, 'ã': 228, 'ä': 229, 'å': 230, 'æ': 231, 'ç': 232, 'è': 233, 'é': 234, 'ê': 235, 'ë': 236, 'ì': 237, 'í': 238, 'î': 239, 'ï': 240, 'ð': 241, 'ñ': 242, 'ò': 243, 'ó': 244, 'ô': 245, 'õ': 246, 'ö': 247, '÷': 248, 'ø': 249, 'ù': 250, 'ú': 251, 'û': 252, 'ü': 253, 'ý': 254, 'þ': 255, 'ÿ': 256, b'in': 257, b' t': 258, b'st': 259, b' a': 260, b'er': 261, b'en': 262, b'ing': 263, b' th': 264, b' f': 265, b'te': 266, b're': 267, b'at': 268, b' b': 269, b'on': 270, b' to': 271, b'ou': 272, b' s': 273, b' m': 274, b'le': 275, b' in': 276, b'ken': 277, b' o': 278, b'ab': 279, b' p': 280, b'ra': 281, b' v': 282, b' i': 283, b'ge': 284, b'rain': 285, b' the': 286, b'ct': 287, b'ion': 288, b' (': 289, b'yte': 290, b' vo': 291, b' voc': 292, b' vocab': 293, b'la': 294, b' re': 295, b' an': 296, b' train': 297, b'th': 298, b'lar': 299, b'ro': 300, b'to': 301, b'un': 302, b' te': 303, b' B': 304, b' BP': 305, b' BPE': 306, b' training': 307, b'ld': 308, b' w': 309, b' d': 310, b' vocabu': 311, b' vocabular': 312, b' vocabulary': 313, b'token': 314, b'li': 315, b' that': 316, b've': 317, b'our': 318, b'll': 319, b' byte': 320, b'ed': 321, b' mer': 322, b' of': 323, b'ction': 324, b' token': 325, b'iz': 326, b'ould': 327, b'al': 328, b' and': 329, b'pe': 330, b' li': 331, b' list': 332, b' T': 333, b' n': 334, b' merge': 335, b' bytes': 336, b'ple': 337, b'ent': 338, b' be': 339, b' c': 340, b' test': 341, b' y': 342, b'or': 343, b' fun': 344, b' function': 345, b'ut': 346, b' sh': 347, b' should': 348, b' pa': 349, b'str': 350, b' P': 351, b' wi': 352, b' A': 353, b' ma': 354, b'ial': 355, b' fro': 356, b' from': 357, b' Th': 358, b'is': 359, b' merges': 360, b'pp': 361, b' is': 362, b' or': 363, b'ment': 364, b'ath': 365, b' inp': 366, b' input': 367, b' fi': 368, b' tokeniz': 369, b' tokenizer': 370, b' Y': 371, b' Your': 372, b'an': 373, b'ast': 374, b'me': 375, b'ter': 376, b'es': 377, b' pro': 378, b' spe': 379, b' spec': 380, b' special': 381, b').': 382, b' do': 383, b' no': 384, b' <': 385, b'der': 386, b'ation': 387, b' tests': 388, b' you': 389, b' im': 390, b' imple': 391, b' implement': 392, b'ad': 393, b'run': 394, b' u': 395, b'ke': 396, b'sing': 397, b' Py': 398, b'ui': 399, b'ly': 400, b' su': 401, b' rege': 402, b' regex': 403, b' W': 404, b'ven': 405, b' tex': 406, b' text': 407, b' file': 408, b'byte': 409, b' h': 410, b' le': 411, b'ow': 412, b'ters': 413, b' str': 414, b' with': 415, b'ize': 416, b' int': 417, b'si': 418, b'ive': 419, b'ines': 420, b'um': 421, b' ite': 422, b' item': 423, b' prod': 424, b' produ': 425, b' produc': 426, b' produced': 427, b' any': 428, b' tokens': 429, b' ad': 430, b' not': 431, b'ect': 432, b'tu': 433, b'su': 434, b' di': 435, b' The': 436, b' I': 437, b'ch': 438, b'),': 439, b'as': 440, b' order': 441, b' your': 442, b' will': 443, b' ne': 444, b'ap': 445, b'train': 446, b'bpe': 447, b' run': 448, b'py': 449, b' O': 450, b'ts': 451, b' me': 452, b' using': 453, b'gu': 454, b'age': 455, b' for': 456, b' this': 457, b' Pyth': 458, b' Python': 459, b' make': 460, b' sure': 461, b'ave': 462, b' bui': 463, b' build': 464, b'ppor': 465, b' mo': 466, b' most': 467, b' fast': 468, b'De': 469, b'Deli': 470, b'Deliv': 471, b'Deliver': 472, b'Deliverab': 473, b'Deliverable': 474, b' Wr': 475, b' Wri': 476, b' Write': 477, b' g': 478, b' gi': 479, b' given': 480, b' path': 481, b' trains': 482, b'leve': 483, b'level': 484, b' han': 485, b' hand': 486, b' handle': 487, b' least': 488, b' fo': 489, b' foll': 490, b' follow': 491, b' following': 492, b' para': 493, b' parame': 494, b' parameters': 495, b'path': 496, b' Path': 497, b' dat': 498, b' data': 499, b'size': 500, b' po': 501, b' posi': 502, b' posit': 503, b' positive': 504, b' inte': 505, b' integ': 506, b' integer': 507, b' de': 508, b' def': 509, b' defines': 510, b' max': 511, b' maxi': 512, b' maxim': 513, b' maximum': 514, b' fin': 515, b' final': 516, b' size': 517, b'inc': 518, b'incl': 519, b'inclu': 520, b'includ': 521, b'including': 522, b' ini': 523, b' init': 524, b' initial': 525, b' items': 526, b' merg': 527, b' merging': 528, b'tokens': 529, b' string': 530, b' strings': 531, b' add': 532, b' Thes': 533, b' These': 534, b' oth': 535, b' other': 536, b' otherw': 537, b' otherwis': 538, b' otherwise': 539, b' af': 540, b' aff': 541, b' affect': 542, b' retu': 543, b' retur': 544, b' return': 545, b' resu': 546, b' resul': 547, b' result': 548, b' resulting': 549, b' dict': 550, b'int': 551, b' mapp': 552, b' mapping': 553, b' ID': 554, b'tuple': 555, b'bytes': 556, b']]': 557, b' E': 558, b' Ea': 559, b' Each': 560, b' tu': 561, b' tuple': 562, b' (<': 563, b'>,': 564, b'>),': 565, b' rep': 566, b' repre': 567, b' repres': 568, b' represent': 569, b' representing': 570, b' was': 571, b' merged': 572, b'>.': 573, b' ordered': 574, b' by': 575, b' cre': 576, b' creation': 577, b' To': 578, b' ag': 579, b' aga': 580, b' again': 581, b' against': 582, b' our': 583, b' prov': 584, b' provi': 585, b' provid': 586, b' provided': 587, b' fir': 588, b' first': 589, b' need': 590, b' adap': 591, b' adapter': 592, b' at': 593, b' [': 594, b'adap': 595, b'adapters': 596, b'].': 597, b' Then': 598, b' uv': 599, b' pyte': 600, b' pytest': 601, b'test': 602, b' implementation': 603, b' ab': 604, b' able': 605, b' pas': 606, b' pass': 607, b' all': 608, b' Op': 609, b' Opt': 610, b' Option': 611, b' Optiona': 612, b' Optionall': 613, b' Optionally': 614, b'this': 615, b' could': 616, b' lar': 617, b' large': 618, b' ti': 619, b' time': 620, b'inve': 621, b'invest': 622, b'investment': 623, b' can': 624, b' ke': 625, b' key': 626, b' par': 627, b' parts': 628, b' meth': 629, b' metho': 630, b' method': 631, b' so': 632, b' some': 633, b' sy': 634, b' syst': 635, b' syste': 636, b' system': 637, b' systems': 638, b' la': 639, b' lan': 640, b' langu': 641, b' language': 642, b' inst': 643, b' instan': 644, b' instanc': 645, b' instance': 646, b' C': 647, b'++': 648, b'con': 649, b'consi': 650, b'consider': 651, b' cpp': 652, b' cppy': 653, b' cppyy': 654, b' R': 655, b' Ru': 656, b' Rust': 657, b'using': 658, b' PyO': 659, b' If': 660, b' aw': 661, b' awa': 662, b' aware': 663, b' wh': 664, b' whi': 665, b' which': 666, b' op': 667, b' oper': 668, b' operation': 669, b' operations': 670, b' req': 671, b' requi': 672, b' require': 673, b' co': 674, b' copy': 675, b' copying': 676, b' vs': 677, b' read': 678, b' reading': 679, b' dire': 680, b' direct': 681, b' directly': 682, b' mem': 683, b' memor': 684, b' memory': 685, b' leave': 686, b' instr': 687, b' instru': 688, b' instruction': 689, b' instructions': 690, b' it': 691, b' builds': 692, b' on': 693, b' only': 694, b' py': 695, b' pyp': 696, b' pypro': 697, b' pyproj': 698, b' pyproject': 699, b'tom': 700, b'toml': 701, b' Al': 702, b' Als': 703, b' Also': 704, b' note': 705, b' G': 706, b' GP': 707, b' GPT': 708, b' we': 709, b' well': 710, b'suppor': 711, b'supporte': 712, b'supported': 713, b' en': 714, b' eng': 715, b' engines': 716, b' too': 717, b' sl': 718, b' slow': 719, b' We': 720, b' have': 721, b' ver': 722, b' veri': 723, b' verif': 724, b' verifi': 725, b' verified': 726, b' On': 727, b' Oni': 728, b' Onigu': 729, b' Onigur': 730, b' Onigurum': 731, b' Oniguruma': 732, b' reas': 733, b' reason': 734, b' reasonab': 735, b' reasonably': 736, b' suppor': 737, b' supports': 738, b' neg': 739, b' negat': 740, b' negative': 741, b' l': 742, b' lo': 743, b' loo': 744, b' look': 745, b' looka': 746, b' lookah': 747, b' lookahe': 748, b' lookahead': 749, b' but': 750, b' pac': 751, b' pack': 752, b' package': 753, b' if': 754, b' anyth': 755, b' anything': 756, b' e': 757, b' even': 758, b' faster': 759}\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "import collections\n",
    "\n",
    "PAT = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "ENC = \"UTF-8\"\n",
    "\n",
    "\n",
    "def pre_tokenize(input_path: str) -> dict[tuple[bytes], int]:\n",
    "    \"\"\"Get the initial coarse-grained frequencies using regex\"\"\"\n",
    "\n",
    "    with open(input_path) as f:\n",
    "        contents = f.read()\n",
    "\n",
    "    freqs: dict[tuple[bytes], int] = {}\n",
    "\n",
    "    for match in re.finditer(PAT, contents):\n",
    "        match_str = match.group()\n",
    "        match_bytes = tuple(c.encode() for c in match_str)\n",
    "\n",
    "        if match_bytes not in freqs:\n",
    "            freqs[match_bytes] = 0\n",
    "\n",
    "        freqs[match_bytes] += 1\n",
    "\n",
    "    return freqs\n",
    "\n",
    "\n",
    "def get_pair_freqs(freqs: dict[tuple[bytes], int]) -> dict[tuple[bytes, bytes], int]:\n",
    "    \"\"\"Get the frequencies of each byte pair from the coarse-grained frequencies table\"\"\"\n",
    "\n",
    "    pairs: dict[tuple[bytes, bytes], int] = collections.defaultdict(int)\n",
    "\n",
    "    for symbols, freq in freqs.items():\n",
    "        for i in range(len(symbols) - 1):\n",
    "            pairs[symbols[i], symbols[i + 1]] += freq\n",
    "\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def merge(freqs: dict[tuple[bytes], int], pair: tuple[bytes, bytes]) -> dict[tuple[bytes], int]:\n",
    "    \"\"\"Merge the pair in the table of coarse-grained frequencies\n",
    "\n",
    "    Example: {(b'i', b'b', b'c'): 5} -> {(b'i', b'bc'): 5}\n",
    "    \"\"\"\n",
    "\n",
    "    new_freqs = {}\n",
    "\n",
    "    for symbols, freq in freqs.items():\n",
    "        new_symbols = []\n",
    "        i = 0\n",
    "        while i < len(symbols):\n",
    "            if i < len(symbols) - 1 and symbols[i] == pair[0] and symbols[i + 1] == pair[1]:\n",
    "                # Merge the pair\n",
    "                new_symbols.append(pair[0] + pair[1])\n",
    "                i += 2\n",
    "            else:\n",
    "                new_symbols.append(symbols[i])\n",
    "                i += 1\n",
    "\n",
    "        new_freqs[tuple(new_symbols)] = new_freqs.get(tuple(new_symbols), 0) + freq\n",
    "\n",
    "    return new_freqs\n",
    "\n",
    "\n",
    "def train_bpe(\n",
    "    input_path: str, vocab_size: int, special_tokens: list[str]\n",
    ") -> tuple[dict[int, bytes], list[tuple[bytes, bytes]]]:\n",
    "    \"\"\"Trains a byte-level BPE tokenizer with the specified `vocab_size` on the\n",
    "    text in the file at `input_path.\n",
    "\n",
    "    Returns:\n",
    "    - vocab: dict[int,bytes]\n",
    "    - merges: list[tuple[bytes,bytes]]\n",
    "    \"\"\"\n",
    "    initial_tokens = special_tokens + [chr(i) for i in range(256)]\n",
    "    vocab = {token: i for i, token in enumerate(initial_tokens)}\n",
    "    merges = []\n",
    "\n",
    "    # Coarse-grained frequencies,\n",
    "    # e.g. {(b'l', b'o',b 'w', b'e', b'r'): 12, (b'h', b'i',b'g', b'h'): 3, ...}\n",
    "    freqs = pre_tokenize(input_path)\n",
    "\n",
    "    n_initial_tokens = len(initial_tokens)\n",
    "    n_merges = vocab_size - n_initial_tokens\n",
    "\n",
    "    for i in range(n_initial_tokens, n_initial_tokens + n_merges):\n",
    "        # Pair frequencies, e.g. {(b'a', b'b'): 2, (b'c, b'de'): 12, ...}\n",
    "        pairs = get_pair_freqs(freqs)\n",
    "\n",
    "        # If max. vocab size is larger than largest possible vocab for provided data\n",
    "        if not pairs:\n",
    "            break\n",
    "\n",
    "        # Most frequent pair, e.g. (b'a', b'be')\n",
    "        best = max(pairs, key=lambda x: pairs.get(x))\n",
    "\n",
    "        # Create new vocab entry from most frequent pair\n",
    "        vocab[best[0] + best[1]] = i\n",
    "\n",
    "        # Replace individual tokens with pair in coarse-grained frequencies\n",
    "        freqs = merge(freqs, best)\n",
    "\n",
    "        # Append to merges\n",
    "        merges.append(best)\n",
    "\n",
    "    return (vocab, merges)\n",
    "\n",
    "\n",
    "\n",
    "(vocab, merges) = train_bpe(\"./data/tiny.txt\", 1024, [\"<|endoftext|>\"])\n",
    "\n",
    "print(merges)\n",
    "print(vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
